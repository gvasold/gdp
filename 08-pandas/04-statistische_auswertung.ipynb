{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas: Statistische Auswertungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas wurde als Werkzeug für die Datenanalyse entwickelt und ist somit dem Bereich *Data Science* zuzuordnen. Es ist damit natürlich vor allem für statistische Auswertungen geeignet und ist stark an die Möglichkeiten der Programmiersprache `R` angelehnt, die im Bereich der Statitik viel verwendet wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen als DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bisher haben wir immer unsere Daten direkt im Notebook erzeugt. In der Praxis ist es jedoch fast immer so, dass die Daten entweder aus einer Datei oder z.B. einer Datenbank geladen werden. Pandas bietet zu diesem Zweck eine Reihe von Hilfsfunktionen an, wie z.B. `read_csv()`, `read_table()`, `read_json()`, `read_hdf()`,  `read_xml()` usw. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Daten für dieses Notebook lesen wir aus einer CSV (Comma Separated Values) Datei ein. Unsere Beispieldaten stammen von DASL (Data and Story Library: https://dasl.datadescription.com), einer Website, die Daten für Statistikkurse bereit stellt. Der verwendete Datensatz \"Amazon books\" beschreibt 325 Bücher in 12 Spalten: https://dasl.datadescription.com/datafile/amazon-books. Lesen wir die Daten einmal ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "books = pd.read_csv('../data/pandas/amazon-books.txt', sep='\\t', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `read_csv()` Funktion erwartet als erstes Argument den Namen (ggf. mit Verzeichnispfad) der \n",
    "einzulesende Datei. Hier verwenden wir noch zwei weitere Argumente:\n",
    "\n",
    "  * `sep=` gibt den Spaltentrenner der einzulesenden Datei an.\n",
    "    Das 'C' in `CSV` steht ja eigentlich für 'Comma', die CSV Dateien können aber auch zum Beispiel\n",
    "    durch ein Semikolon (`;`) oder ein Tabulaturzeichen (`\\t`) getrennt werden. Streng genommen\n",
    "    liegen unsere Daten also nicht als CSV, sondern als TSV (tabulator separated values) vor.\n",
    "  * `encoding=` gibt die Kodierung an, in der die Daten in der Datei gespeichert sind.\n",
    "\n",
    "Weitere oft nützliche Parameter der `read_csv()` Datei sind:\n",
    "\n",
    "  * `header=0` teilt Pandas mit, dass die erste Zeile bereits Daten und nicht die Spaltennamen enthält\n",
    "  * `names=`  Falls die Daten die Spaltennamen nicht in der ersten Zeile enthalten, können diese mit diesem Parameter vergeben werden\n",
    "      z.B.: `names=['Name', 'Age']`.\n",
    "  * `index_col=` Wird dieser Parameter nicht verwendet, erzeugt Pandas fortlaufende Zahlen als Index. `index_col=`\n",
    "    erwartet den Namen einer Spalte als Wert. Diese Spalte wird dann für den Index verwendet.\n",
    "  * `nrows=`  ist dann nützlich, wenn nicht alle Zeilen, sondern z.B. nur die ersten 100 eingelesen werden sollen. Das\n",
    "    ist vor allem dann nützlich, wenn wir während der Entwicklungsphase uns nicht mit riesigen Datenmengen herumschlagen\n",
    "    wollen.\n",
    "  * `usecols=` wird verwendet, wenn wir nicht alle, sondern nur bestimmte Spalten aus der CSV-Datei\n",
    "    verwenden wollen. Der Wert ist eine List der zu verwendenden Spaltennamen.\n",
    "  * `dtype=` ist praktisch, wenn wir für eine oder mehrere Spalten einen bestimmten Datentyp erzwingen wollen. Fehlt dieser\n",
    "    Parameter, versucht Pandas selbst einen geeigneten Typ zu wählen. Der Wert ist ein Dictionary, in dem der Key der Spaltenname ist\n",
    "    und der Value der zu verwendende Typ. Beispiel:\n",
    "    `pd.read_csv('mydata.csv', dtype={'Alter': 'uint8', 'salary': 'float'}`\n",
    "    Eine Liste der möglichen Typen finden Sie hier: https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#basics-dtypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speichern eines DataFrames\n",
    "\n",
    "Wir haben zwar unsere Daten noch nicht verändert, zeigen aber dennoch bereits hier, wie wir ein DataFrame wieder in eine CSV-Datei schreiben können. Pandas stellt dazu die Funktion `to_csv()` bereit. Wie beim Einlesen von Daten gibt es auch hier Funktionen für eine Reihe von Ausgabeformaten wie z.B. `to_excel()`,\n",
    "`to_json()`usw.\n",
    "\n",
    "Auch hier gibt es wieder einige Parameter, die verwendet werden können. Beispielsweise kann man mit `columns=[]` die Namen von Spalten festlegen, die in die Datei geschrieben werden sollen. Wir setzen hier das Semicolon als Trennzeichen und wieder 'UTF-8' als Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv('../output/clean_books,csv', sep=';', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Überblick über die Daten\n",
    "\n",
    "Ehe wir etwas Sinnvolles mit den Daten anfangen können, müssen wir sie einmal verstehen. Pandas bietet hier einige Möglickeiten, die wir bereits kennen gelernt habe. Zur Auffrischung wenden wir sie hier auf echte, uns noch nicht bekannte Daten an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausschnitt anzeigen\n",
    "\n",
    "Die `head()` Methode zeigt die ersten 5 Zeilen. Alternativ gibt es noch `tail()`(gibt die letzten 5 Zeilen aus) und `sample()` (gib eine zufällige Zeile aus).\n",
    "\n",
    "Alle Methoden akzeptieren auch eine Zahl, über die die Zahl der ausgegebenen Zeilen gesteuert werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zahl der Zeilen und Spalten\n",
    "\n",
    "`shape` enthält ein Tupel: Zahl der Zeilen und Zahl der Spalten. Bin ich nur an der Zahl der Spalten interessiert kann ich so drauf zugreifen: `shape[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.shape  # Show number of lines and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liste der Spaltennamen\n",
    "\n",
    "`columns` enthält die Spaltennamen als Liste. Die Reihenfolge entspricht der Reihenfolge im DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.columns  # give me list with all column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datentypen der Spalten\n",
    "\n",
    "`dtypes` listet die Spaltennamen und die in den einzelnen Spalten verwendeten Datentypen auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['Pub year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten beim Einlesen adaptieren\n",
    "\n",
    "Hier noch ein Beispiel, in dem wir beim `read_csv()` die eingelesenen Daten manipulieren. \n",
    "\n",
    "  - Wir setzen die Spaltennamen durch unsere eigenen (kürzeren) Spaltennamen\n",
    "  - Wir setzen den Datentyp von `pages` und 'year' auf `Int16', Die explizite Angabe eines anderen Datentyps würde auch auch für weitere Spalten wie 'price' oder die Maße (width, heigh,m weight) Sinn machen. Allerdings stehen wir hier vor dem Problem,\n",
    "    dass die meisten Datentypen (noch?) nicht *nullable* sind. Deshalb würde es beim Einlesen Fehler geben, wenn ein Wert fehlt.\n",
    "\n",
    "Das hier erzeugte DataFrame dient nur zur Demonstartion der Möglichkeiten. In der Folge werden wir das zuerst erzeugte DataFrame mit den originalen Spaltennamen und Default-Datentypen verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['title','author','listprice','price','hardcover','pages',\n",
    "                'publisher','year','isbn','height', 'width','thick','weight']\n",
    "column_dtype = {'year':'Int16', 'pages': 'Int16'}\n",
    "\n",
    "amazon_books = pd.read_csv('../data/pandas/amazon-books.txt',sep='\\t',encoding='UTF-8',header = 0, \n",
    "                           names = column_names, dtype = column_dtype)\n",
    "\n",
    "print(f'\\nDatentyp der Spalten\\n\\n{amazon_books.dtypes}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten vorbereiten\n",
    "\n",
    "Ehe wir die Daten auswerten, müssen wir sie in einen Zustand bringen, die eine sinnvolle Auswertung erst ermöglicht. Dazu gehört vor allem die Überprüfung auf fehlende Werte.\n",
    "\n",
    "### Überprüfung auf fehlende Werte\n",
    "\n",
    "Wir haben ja bereits die Methoden `isna()`und `isnull()` kennengelernt. Prüfen wir einmal, ob es überall eine Seitenangabe gibt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.NumPages.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obwohl wir mit 325 Büchern einen sehr kleinen Datensatz haben, ist diese Ausgabenicht mehr wirklich übersichtlich. Daher zählen wir die auf `True` stehenden Ergebnisse aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(books.NumPages.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2` bedeutet hier, dass die Spalte zwei Werte enthält, die nicht als Zahl interpretierbar sind. Wie finden wir nun heraus, welche das sind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books[books.NumPages.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`isna()` können wir auch auf einen ganzen DataFrame ausführen und so alle Spalten finden, in denen ein `NaN` Wert vorkommt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man das Problemmit den fehlenden Werten löst, ist nicht verallgemeinerbar. Je nach Datenlage und Auswertungsabsicht könnte man die `NaN` Werte durch einen Defaultwert ersetzen, bei kleinen Datensammlungen vielleicht nachrecherchieren usw. Die einfachste Lösung, insbesondere, wenn man einen großen Datenbestand hat, liegt in der Entfernung solcher Zeilen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_books = books.dropna()\n",
    "clean_books.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistische Kennzahlen\n",
    "\n",
    "### Überblick mit describe()\n",
    "\n",
    "Die Methode `describe()` generiert folgende statistische Kennzahlen für numerische Daten:\n",
    "\n",
    "   * `count` ist die Zahl der (gültigen) Werte (Zeilen)\n",
    "   * `mean` ist das arithmetische Mittel\n",
    "   * `std` ist die Standardabweichung (durchschnittliche Abweichung vom Mittelwert)\n",
    "   * `min` ist das Minimum, also der kleinste vorkommende Wert\n",
    "   * `max` ist das Maximum, also der größe vorkommende Wert\n",
    "   * `25` ist das erste Quartil. Also der Wert, der die Grenze zwischen dem ersten und zweiten Viertel der sortieren Werte darstellt.\n",
    "   * `50` ist das zweite Quartil. Also der Wert, der die Grenze zwischen dem zweiten und dritten Viertel der sortieren Werte darstellt. Dies entspricht dem Median.\n",
    "   * `75` ist das dritte Quartil. Also der Wert, der die Grenze zwischen dem dritten und vierten Viertel der sortieren Werte darstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_books.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Sache übersichtlicher zu machen, runden wir die Werte auf zwei Nachkommastellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_books.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das funktioniert natürlich nur für numerische Werte. Wir können aber auch für nicht numerische Werte einen Überblick generieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_books['Author'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis ist so zu lesen:\n",
    "\n",
    "  * Es wurden 310 Werte gefunden, davon waren 243 unique. Oder anderes gesagt: es wurden 243 unterschiedliche Autoren gefunden.\n",
    "  * Am öftesten kommt der Wert 'Vladimir Nabokov' vor, nämlich sieben Mal. Hier müssen wir ein wenig aufpassen, weil hier immer nur ein Wert ausgegeben wird. Hätten wir einen zweiten Autor mit 7 Büchern, würde dieser in dieser Ausgabe unterschlagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir nicht-numerische Spalten in die durch `describe()` generierte Ausgabe aufnehmen wollen, müssen wir angeben, dass alle Spalten mit bestimmten Datentypen berücksichtigt werden sollen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_books.describe(include=['object', 'int', float]).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einzelne Kennzahlen\n",
    "\n",
    "Ist man nur an einem bestimmten statistischen Wert interessiert, gibt es entsprechende Methoden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum und Maximum\n",
    "\n",
    "`min()` und `max()` ermitteln den kleinsten bzw. größten Wert der Spalte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_books.NumPages.min())\n",
    "print(clean_books.NumPages.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arithemtisches Mittel\n",
    "\n",
    "Der Mittelwert wird über die Methode `mean()` ermittelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_books[\"List Price\"].mean().round(2))\n",
    "print(clean_books[\"Amazon Price\"].mean().round(2))\n",
    "print(clean_books[\"NumPages\"].mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den Mittelwert sollte man immer zusammen mit der Standardabweichung betrachen. Diese ist über die Methode `std()`verfügbar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Listenpreis: {clean_books[\"List Price\"].mean().round(2)} bei einer Standardabweichung von {clean_books[\"List Price\"].std().round(2)}\")\n",
    "print(f\"Amazon Preis: {clean_books[\"Amazon Price\"].mean().round(2)} bei einer Standardabweichung von {clean_books[\"Amazon Price\"].std().round(2)}\")\n",
    "print(f\"Seitenzahl: {clean_books[\"NumPages\"].mean().round(2)} bei einer Standardabweichung von {clean_books[\"NumPages\"].std().round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median\n",
    "\n",
    "Der Median wird so ermittelt, dass man die einzelnen Werte sortiert und dann den (oder die) Werte ermittelt, die genau in der Mitte liegen. Deshalb entspricht der Median auch dem zweiten Quartil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_books.NumPages.median().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Die Quantile\n",
    "Die Quantile gehören zu den so genannten Lagemaßen, die vor allem in der Wahrscheinlichkeitsrechnung eine wichtige Rolle spielen. Dabei werden einfach die Daten sortiert und dann die Grenzen zwischen den Quantilen ermittelt. Dann lässt sich feststellen, in welchem Quantil ein Wert liegt. Das klassische Quantil ist das Quartil (Aufteilung in 4 Viertel), aber grundsätzlich kann man z.B. auch Quintile (Fünftel) oder Dezile (Zehntel) ermitteln. Die Aufteilung lässt sich in Pandas als Zahl zwischen 0 und 1 ausdrücken. `0.5` entspricht dabei dem Median, weil gleich viele Werte vor sowie nach dieser Grenze liegen. Probieren wir es aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_books.NumPages.quantile(0.5).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir das erste Quartil haben wollen, müssen wir `0.25` angeben, `0.75` für das dritte Quartil usw. Für die Ermittlung der Grenze für das erste Dezil müssen wir `0.1` angeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_books.NumPages.quantile(0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modus\n",
    "\n",
    "Der Modus (d.h. der häufigste Wert) lässt sich mit der Methode `mode()` ermitteln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_books.NumPages.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Varianz\n",
    "\n",
    "Die Varianz ist das Quadrat der mittleren Abweichungen. Die entsprechende Methode heißt in Pandas `var()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_books.NumPages.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Werte auszählen\n",
    "\n",
    "### Zahl der Werte\n",
    "\n",
    "Um zu ermitteln, wie viele Werte in einer Spalte vorhanden sind, verwenden wir die Methode `count()`. Diese ignoriert fehlende Werte. Sie enspricht also nicht der Zahl der Zeilen, sondern ist der Zahl der Werte in einer Spalte, die nicht `None` sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(books.Author.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falls wir die Zahl distinkten Werte (also ohne mehrfache Vorkommen) brauchen, bietet sich die `nunique()` Methode an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.Author.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schließlich lernen wir noch eine letzte Methode kennen: `value_counts()`. Diese gruppiert im Hintergrund nach Werten und zählt dann die Werte pro Gruppe. Auf diese Art können wir ganz einfach ermitteln, wie viele Bücher eines jeden Autors bzw. jeder Autorin vorhanden sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.Author.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lizenz\n",
    "\n",
    "This notebook ist part of the course [Grundlagen der Programmierung](https://github.com/gvasold/gdp) held by [Gunter Vasold](https://online.uni-graz.at/kfu_online/wbForschungsportal.cbShowPortal?pPersonNr=51488) at Graz University 2017&thinsp;ff. \n",
    "\n",
    "<p>\n",
    "    It is licensed under <a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0\">CC BY-NC-SA 4.0</a>\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "    <td>\n",
    "        <img style=\"height:22px\" \n",
    "             src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1\"/></li>\n",
    "    </td>\n",
    "    <td>\n",
    "    <img style=\"height:22px;\"\n",
    "         src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1\" /></li>\n",
    "    </td>\n",
    "    <td>\n",
    "        <img style=\"height:22px;\"\n",
    "         src=\"https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1\" /></li>\n",
    "    </td>\n",
    "    <td>\n",
    "        <img style=\"height:22px;\"\n",
    "             src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1\" /></li>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
